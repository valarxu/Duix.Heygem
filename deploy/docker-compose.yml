networks:
  ai_network:
    driver: bridge

volumes:
  redis_data:
    driver: local

services:
  heygem-tts:
    image: guiji2025/fish-speech-ziming
    container_name: heygem-tts
    restart: always
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=0
      - NVIDIA_DRIVER_CAPABILITIES=compute,graphics,utility,video,display
    ports:
      - '18180:8080'
    volumes:
      - d:/heygem_data/voice/data:/code/data
    command: /bin/bash -c "/opt/conda/envs/python310/bin/python3 tools/api_server.py --listen 0.0.0.0:8080"
    networks:
      - ai_network
  heygem-asr:
    image: guiji2025/fun-asr
    container_name: heygem-asr
    restart: always
    runtime: nvidia
    privileged: true
    working_dir: /workspace/FunASR/runtime
    ports:
      - '10095:10095'
    command: sh /run.sh
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    networks:
      - ai_network
  heygem-gen-video:
    image: guiji2025/heygem.ai
    container_name: heygem-gen-video
    restart: always
    runtime: nvidia
    privileged: true
    volumes:
      - d:/heygem_data/face2face:/code/data
    environment:
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    shm_size: '8g'
    ports:
      - '8383:8383'
    command: python /code/app_local.py
    networks:
      - ai_network
    
  # 添加Redis服务
  redis:
    image: redis:7-alpine
    container_name: heygem-redis
    restart: always
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - ai_network
    command: >
      redis-server 
      --appendonly yes 
      --appendfsync everysec 
      --maxmemory 512mb 
      --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # 添加队列管理服务
  queue-manager:
    image: node:18-alpine
    container_name: heygem-queue
    restart: always
    volumes:
      - ./queue-service:/app
      - d:/heygem_data:/data/heygem_data
      - /app/node_modules  # 匿名卷，避免本地node_modules覆盖
    working_dir: /app
    command: sh -c "npm install --production && npm start"
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - ALLOWED_ORIGINS=*
    depends_on:
      redis:
        condition: service_healthy
      heygem-gen-video:
        condition: service_started
    networks:
      - ai_network
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # 添加Nginx代理服务
  nginx-proxy:
    image: nginx:alpine
    container_name: heygem-nginx
    restart: always
    ports:
      - "80:80"
    volumes:
      - ./nginx-proxy.conf:/etc/nginx/conf.d/default.conf:ro
      - d:/heygem_data:/data/heygem_data:ro
    depends_on:
      queue-manager:
        condition: service_healthy
      heygem-gen-video:
        condition: service_started
    networks:
      - ai_network
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
